import dotenv from "dotenv";
dotenv.config({ path: ".env.local" });

import { fileURLToPath } from 'url';
import path from 'path';
const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

import fs from 'fs';
import axios from 'axios';
import { execSync } from 'child_process';
import { createClient } from '@supabase/supabase-js';
import crypto from 'crypto';
import FormData from 'form-data';

dotenv.config();

// üü° ◊ò◊ï◊¢◊ü ◊ê◊™ ◊î÷æstoryboard.json
const storyboardPath = path.join(__dirname, '../storyboard/story.json');

if (!fs.existsSync(storyboardPath)) {
  console.error('‚ùå storyboard/story.json not found.');
  process.exit(1);
}

const storyboard = JSON.parse(fs.readFileSync(storyboardPath, 'utf-8'));

// üü° ◊û◊ï◊ï◊ì◊ê ◊©◊î÷ævoiceId ◊ß◊ô◊ô◊ù
const voiceId = storyboard.voiceId;
if (!voiceId) {
  console.error('‚ùå voiceId is missing in storyboard/story.json.');
  process.exit(1);
}

// üü° ◊û◊ê◊ó◊ì ◊ê◊™ ◊õ◊ú ◊î◊ò◊ß◊°◊ò◊ô◊ù ◊ú◊°◊ß◊®◊ô◊§◊ò ◊ê◊ó◊ì
interface Scene {
  text: string;
}

const text = (storyboard.scenes as Scene[])?.map(scene => scene.text).join(' ') || '';
if (!text) {
  console.error('‚ùå No scene texts found in storyboard.');
  process.exit(1);
}

// üü° ◊î◊í◊ì◊®◊ï◊™ ◊°◊ë◊ô◊ë◊™◊ô◊ï◊™
const elevenApiKey = process.env.ELEVENLABS_API_KEY;
const supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL;
const supabaseKey = process.env.SUPABASE_SERVICE_ROLE_KEY;
const openaiApiKey = process.env.OPENAI_API_KEY;

if (!elevenApiKey || !supabaseUrl || !supabaseKey || !openaiApiKey) {
  console.error('‚ùå Missing required environment variables:');
  if (!elevenApiKey) console.error('   - ELEVENLABS_API_KEY');
  if (!supabaseUrl) console.error('   - NEXT_PUBLIC_SUPABASE_URL');
  if (!supabaseKey) console.error('   - SUPABASE_SERVICE_ROLE_KEY');
  if (!openaiApiKey) console.error('   - OPENAI_API_KEY');
  process.exit(1);
}

// üü° ◊†◊™◊ô◊ë◊ô ◊ß◊ë◊¶◊ô◊ù
const videoId = crypto.randomUUID();
const outputDir = path.join(__dirname, `../renders/${videoId}`);
const audioPath = path.join(outputDir, 'audio.mp3');
const captionsVttPath = path.join(outputDir, 'captions.vtt');
const captionsSrtPath = path.join(outputDir, 'captions.srt');

// üü° ◊ó◊ô◊ë◊ï◊® ◊ú÷æSupabase
const supabase = createClient(supabaseUrl, supabaseKey);

// ‚úÖ ◊§◊ï◊†◊ß◊¶◊ô◊ô◊™ ◊ô◊¶◊ô◊®◊™ TTS
async function generateTTS(text: string) {
  console.log('üé§ Generating TTS audio...');
  console.log(`   Voice ID: ${voiceId}`);
  console.log(`   Text length: ${text.length} characters`);
  
  try {
    const response = await axios.post(
      `https://api.elevenlabs.io/v1/text-to-speech/${voiceId}`,
      {
        text,
        model_id: "eleven_multilingual_v2",
        voice_settings: {
          stability: 0.4,
          similarity_boost: 0.75
        }
      },
      {
        headers: {
          "xi-api-key": elevenApiKey,
          "Content-Type": "application/json"
        },
        responseType: 'arraybuffer'
      }
    );

    fs.mkdirSync(outputDir, { recursive: true });
    fs.writeFileSync(audioPath, response.data);
    console.log('‚úÖ TTS audio saved at', audioPath);
  } catch (error: any) {
    console.error('‚ùå TTS generation failed:');
    if (error.response?.data?.error?.message) {
      console.error(`   Error: ${error.response.data.error.message}`);
    } else {
      console.error(`   Error: ${error.message}`);
    }
    throw error;
  }
}

async function transcribeAudio() {
  console.log(' Transcribing audio to captions...');
  
  // Validate audio file exists
  if (!fs.existsSync(audioPath)) {
    const error = `Audio file not found at: ${audioPath}`;
    console.error(`‚ùå ${error}`);
    throw new Error(error);
  }
  
  // Validate audio file size
  const audioStats = fs.statSync(audioPath);
  if (audioStats.size === 0) {
    const error = `Audio file is empty: ${audioPath}`;
    console.error(`‚ùå ${error}`);
    throw new Error(error);
  }
  
  console.log(`   Audio file: ${audioPath}`);
  console.log(`   File size: ${audioStats.size} bytes`);
  
  try {
    // Create form data with proper structure
    const formData = new FormData();
    formData.append('file', fs.createReadStream(audioPath), {
      filename: 'audio.mp3',
      contentType: 'audio/mpeg'
    });
    formData.append('model', 'whisper-1');
    formData.append('response_format', 'vtt');
    
    console.log('   Sending request to OpenAI Whisper API...');
    
    const response = await axios.post(
      'https://api.openai.com/v1/audio/transcriptions',
      formData,
      {
        headers: {
          'Authorization': `Bearer ${openaiApiKey}`,
          ...formData.getHeaders()
        },
        timeout: 60000 // 60 second timeout
      }
    );
    
    if (!response.data) {
      throw new Error('Empty response from Whisper API');
    }
    
    // Save VTT captions
    fs.writeFileSync(captionsVttPath, response.data);
    console.log('‚úÖ Captions VTT saved');
    
    // Convert VTT to SRT using FFmpeg
    console.log('üîÑ Converting VTT to SRT format...');
    execSync(`ffmpeg -i "${captionsVttPath}" "${captionsSrtPath}"`);
    console.log('‚úÖ Captions SRT converted');
    
  } catch (error: any) {
    console.error('‚ùå Audio transcription failed:');
    
    if (error.response?.data?.error?.message) {
      console.error(`   OpenAI Error: ${error.response.data.error.message}`);
    } else if (error.response?.status) {
      console.error(`   HTTP ${error.response.status}: ${error.response.statusText}`);
      if (error.response.data) {
        console.error(`   Response: ${JSON.stringify(error.response.data)}`);
      }
    } else if (error.code === 'ENOTFOUND') {
      console.error('   Network Error: Could not connect to OpenAI API');
    } else if (error.code === 'ECONNABORTED') {
      console.error('   Timeout Error: Request took too long');
    } else {
      console.error(`   Error: ${error.message}`);
    }
    
    throw error;
  }
}

async function uploadToSupabase() {
  console.log('‚òÅÔ∏è Uploading files to Supabase...');
  
  try {
    const audioData = fs.readFileSync(audioPath);
    const srtData = fs.readFileSync(captionsSrtPath);

    const { data: audioUpload, error: audioError } = await supabase.storage
      .from('videos')
      .upload(`${videoId}/audio.mp3`, audioData, { contentType: 'audio/mpeg' });

    const { data: srtUpload, error: srtError } = await supabase.storage
      .from('videos')
      .upload(`${videoId}/captions.srt`, srtData, { contentType: 'text/plain' });

    if (audioError || srtError) {
      console.error('‚ùå Supabase upload failed:');
      if (audioError) console.error(`   Audio upload: ${audioError.message}`);
      if (srtError) console.error(`   SRT upload: ${srtError.message}`);
      throw new Error('Supabase upload failed');
    }

    console.log('‚úÖ Files uploaded to Supabase successfully');
  } catch (error: any) {
    console.error('‚ùå Supabase upload failed:', error.message);
    throw error;
  }
}

(async () => {
  const startTime = Date.now();
  console.log('üé¨ Starting TTS rendering process...');
  console.log(`   Video ID: ${videoId}`);
  
  try {
    await generateTTS(text);
    await transcribeAudio();
    await uploadToSupabase();
    
    const duration = Date.now() - startTime;
    console.log('\nüéâ TTS rendering completed successfully!');
    console.log(`   Duration: ${duration}ms`);
    console.log(`   Video ID: ${videoId}`);
    console.log(`   Voice ID: ${voiceId}`);
    
  } catch (error: any) {
    console.error('\n‚ùå TTS pipeline failed:', error.message);
    process.exit(1);
  }
})();
